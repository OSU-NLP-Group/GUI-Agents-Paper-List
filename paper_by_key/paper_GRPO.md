# Papers with Keyword: GRPO

- [LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization](https://arxiv.org/abs/2506.09373)
    - Jiaqi Tang, Yuâ€¯Xia, Yiâ€‘Fengâ€¯Wu, Yuweiâ€¯Hu, Yuhuiâ€¯Chen, Qingâ€‘Guoâ€¯Chen, Xiaogangâ€¯Xu, Xiangyuâ€¯Wu, Haoâ€¯Lu, Yanqingâ€¯Ma, Shiyinâ€¯Lu, Qifengâ€¯Chen
    - ğŸ›ï¸ Institutions: (not explicitly stated, likely Chinese research institutions; Unknown)
    - ğŸ“… Date: Juneâ€¯11,â€¯2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [GUI]
    - ğŸ”‘ Key: [framework], [reinforcement learning], [entropy-based localization], [location reward], [GRPO]
    - ğŸ“– TLDR: The paper introduces **Location Preference Optimization (LPO)** to improve GUI agent interaction accuracy. It uses information-entropy-driven zones of interest and a dynamic distance-based reward function. Built atop Group Relative Preference Optimization (GRPO), it enables more precise spatial grounding. Results show SOTA performance on offline benchmarks and real-world online GUI tasks.

- [AgentCPMâ€‘GUI: Building Mobileâ€‘Use Agents with Reinforcement Fineâ€‘Tuning](https://github.com/OpenBMB/AgentCPM-GUI)
    - Zhong Zhang, Yaxi Lu, Yikun Fu, Yupeng Huo, Shenzhi Yang, Yesai Wu, Han Si, Xin Cong, Haotian Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming Liu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, Maosong Sun
    - ğŸ›ï¸ Institutions: Tsinghua, RUC, ModelBest
    - ğŸ“… Date: Juneâ€¯2,â€¯2025
    - ğŸ“‘ Publisher: arXiv (arXiv:2506.01391)
    - ğŸ’» Env: [Mobile]
    - ğŸ”‘ Key: [model], [framework], [dataset], [benchmark], [reinforcement fineâ€‘tuning], [compact action space], [CAGUI], [GRPO]
    - ğŸ“– TLDR: Introduces an 8â€¯B Visionâ€“Language GUI agent for onâ€‘device mobile app interaction. Training uses grounding pre-training, supervised fineâ€‘tuning on 55â€¯K Chinese & English trajectories, and reinforcement fineâ€‘tuning (GRPO). A compact JSON action schema enables low-latency inference. Achieves SOTA on five benchmarks including the new Chinese CAGUI (96â€¯%+ TM, 91â€¯% EM). All code, model, and data released.

- [GUI-R1: A Generalist R1-Style Vision-Language Action Model For GUI Agents](https://arxiv.org/abs/2504.10458)
    - Xiaobo Xia, Run Luo
    - ğŸ›ï¸ Institutions: Unknown
    - ğŸ“… Date: April 14, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [GUI]
    - ğŸ”‘ Key: [framework], [reinforcement learning], [unified action space], [GRPO], [GUI-R1]
    - ğŸ“– TLDR: GUI-R1 introduces a reinforcement learning framework that enhances the capabilities of Large Vision-Language Models (LVLMs) for GUI agents. By employing a unified action space and a rule-based reward function, the model efficiently learns to perform high-level tasks across multiple platforms, including Windows, Linux, MacOS, Android, and Web. Utilizing only 0.02% of the data compared to previous methods, GUI-R1 demonstrates superior performance on eight benchmarks, showcasing the potential of reinforcement learning in GUI agent tasks.

- [UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning](https://arxiv.org/abs/2503.21620)
    - Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Guanjing Xiong, Hongsheng Li
    - ğŸ›ï¸ Institutions: vivo AI Lab, MMLab @ CUHK
    - ğŸ“… Date: March 27, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Mobile]
    - ğŸ”‘ Key: [framework], [dataset], [reinforcement learning], [UI-R1-3B], [GRPO], [AndroidControl], [ScreenSpot-Pro]
    - ğŸ“– TLDR: This paper introduces **UI-R1**, a framework that enhances the reasoning capabilities of multimodal large language models (MLLMs) for GUI action prediction tasks through rule-based reinforcement learning. Utilizing a small, high-quality dataset of 136 challenging mobile tasks, the authors design a unified rule-based action reward function and optimize the model using Group Relative Policy Optimization (GRPO). The resulting model, **UI-R1-3B**, demonstrates significant improvements over the base model (Qwen2.5-VL-3B) on both in-domain (AndroidControl) and out-of-domain (ScreenSpot-Pro) benchmarks, showcasing the effectiveness of rule-based RL in advancing GUI understanding and control.
